---
title: "GIS course @ yDiv"
author: "Emilio Berti"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output:
  rmdformats::readthedown:
    toc_depth: 6
    number_sections: true
    theme: united
    highlight: tango
    smart: true
    fig_width: 4
    fig_height: 4
    fig_caption: true
    df_print: paged
    code_folding: show
    keep_md: true
---

<!--   pdf_document:
    toc_depth: 6
    number_sections: true
    highlight: tango
    fig_width: 4
    fig_height: 4
    fig_caption: true
    df_print: paged
    keep_md: true -->

<!-- Page width -->
```{css, echo = FALSE}
#content{
  max-width:1000px;
}
``` 
<style>
blockquote.nb {
  border-left: 5px solid #a82020;
  padding: 5px 10px;
  margin: 20px 0;
  background-color: #ffe0e0;
  font-size: 14px;
  font-weight: bold;
  font-style: normal;
  position: relative;
}

blockquote.nb::before {
  content: "NB";
  position: absolute;
  top: 50%;
  left: -40px; /* Move outside the block */
  transform: translateY(-50%);
  background: #a82020;
  color: white;
  font-weight: bold;
  font-size: 14px;
  padding: 5px 10px;
  border-radius: 3px;
}
</style>

```{r utils, include=FALSE}
highlight <- function(x, pattern) {
  gsub(
    pattern,
    paste0("\033[0;41m", pattern,"\033[0m"),
    x
  )
}
```

# Introduction {.tabset}

This document is a living tutorial that mirrors the lectures of the yDiv course "An Introduction to GIS for Ecology", held at iDiv in Leipzig.
In this two day course we will cover the very basics of GIS, focusing especially on applications to ecology.
During the first day, we will get to know the main data types of GIS, that is geometries and rasters.
During the second day, we will learn some of the most used GIS operations.
You will also start your own individual/group project.
The aims of this course are to

  - Familiarize yourself with basic GIS data and operations
  - Start a project of your interest
  - Getting some simple figures/analyses started

Do **not** expect to become a world-leading GIS expert by the end of the course; this is a basic introductory course (and GIS is quite hard to master).

At the end of each section, you will find multiple exercises; they are not mandatory, but they will help you.
Before starting, be sure to have your machine set up properly.
Also, you can download all data used in this tutorial by clicking [here](teaching/gis-ydiv/data.zip).

## Set up

  - R installed.
  - `terra` installed.
  - `codetools` installed (optional, used by `terra` to perform code checks).
  - Download the [data archive](https://emilio-berti.github.io/teaching/gis-ydiv/data.zip) and decompress it.

Try run `library(terra)`. If it works, good news. If it does not, contact me some days before the course starts.

```{r setup, echo=FALSE}
library(terra)
```

## Data Sets {.tabset}
In this tutorial, we will use data sets for:

  - NDVI for the year 2024 in Leipzig, obtained from Sentinel2 (`ndvi-2024.tif`).
  - Landcover of Leipzig in 2015, obtained from the German Aerospace Center (DLR; `landcover-2015.tif`).
  - Average annual surface temperature from WorldClim (`wc2-bio1.tif`)
  - Bioclimatic variables from WorldClim (`bios.tif`)
  - Digital elevation model from WorldClim (`wc2-elevation.tif`)

## Lecturers {.tabset}

### Emilio Berti (TiBS)
![](figures/emilio.png)

 - Theory in Biodiversity Science
 - Macroecologist / biogeographer
 - Theoretical ecologists

### Guilherme Pinto (BioEcon)

# Data Types

There are two main data types used in GIS:

  1. Geometries (also called vectors or shapes). This usually has extension `.shp`.
  2. Rasters. This usually has extension `.tif`.

They fill two different needs, namely to represent structures that can be well approximated using geometric objects, such as lines, circles, etc., 
and to represent grid data over an area.

If you have produced figures for a manuscript, you are actually already familiar with these type of data.
Images can be saved as vector graphics, where each element is represented by a vector/geometry, or as a matrix/raster of pixels.
This is an old topic in computer graphics, and a nice summary can be found on Adobe website: <https://www.adobe.com/creativecloud/file-types/image/comparison/raster-vs-vector.html>.
This analogy is a useful one; remember it.

## Geometries

Structures such as trees, streets, or buildings can be represented by geometric objects.
For instance, a tree can be represented by a point, a street by straight line, and a building by a polygon.
It makes sense to store the data of these types of structures as their geometric representation.
For example, the building we are in and the adjacent street:

```{r idiv-building, class.source="fold-hide", fig.align='center'}
# This code in incomprehensible to you FOR NOW
# Just an example of geometries to show you how they look on a map
idiv <- rast("data/idiv-building.tif")
plotRGB(idiv)
l <- vect(
  rbind(
    c(12.39585, 51.31866),
    c(12.39846, 51.31722)
  ),
  crs = "EPSG:4326"
)
lines(l, col = "green", lw = 5)
idiv <- vect(
  rbind(
    c(12.39573, 51.31794),
    c(12.39645, 51.31765),
    c(12.39664, 51.31812),
    c(12.39602, 51.31849),
    c(12.39573, 51.31794)
  ),
  crs = "EPSG:4326"
) |>
  as.lines() |>
  as.polygons()
idiv$name <- "iDiv building"
idiv$perimeter <- perim(idiv)
idiv$area <- expanse(idiv)
writeVector(idiv, "data/idiv.shp", overwrite = TRUE)
plot(idiv, add = TRUE, col = adjustcolor("blue", alpha.f = .5))
```

Geometries are saved in _vector-_ or _shape-_files (usually with extension `.shp`).
In addition to the geometric representation of the structure, shapefiles also contain metadata for the geometric representation, such as its extent and coordinate reference system (we will talk about this later), and for the structure, such as their name, length, etc.
For instance, the geometry of the iDiv building above is:
```{r example-geometry, class.source="fold-hide", }
idiv
```

Note that this structure has one geometry and three attributes/variables (`dimensions: 1, 3 (geometries, attributes)`): `name`, `perimeter` ($m$), and `area` ($m^2$).

### Geometry Types

In `terra`, there are three main geometry types:

  1. Points: they are defined by a vector with two values for coordinates (e.g., longitude and latitude)
  2. Lines: they are a series of points connected by straight lines
  3. Polygons: they are a series of lines inscribing a closed area

In `terra`, geometries are created with the function `vect()`.
To create a point geometry, you need to pass a matrix with the coordinates:
```{r create-point}
xy <- cbind(12.39585, 51.31866)  # cbind force it to be a matrix
vect(xy)
```
To create a geometry of multiple points, simply pass a matrix that has multiple rows:
```{r create-points}
xy <- rbind(
  cbind(12.39585, 51.31866),
  cbind(12.39584, 51.31865)
)
poi <- vect(xy)
```

In order to create lines, first create a multi-point geometry, then convert it using `as.lines()`:
```{r create-lines}
xy <- rbind(
  cbind(12.39585, 51.31866),
  cbind(12.39584, 51.31865)
)
lin <- vect(xy) |> as.lines()
```

In order to create polygons, first create a mutli-point geometry, then covert it to lines, and finally to polygons using `as.polygons()`.
The last point should be the same as the first to close the geometry.
A geometry that is not closed does not inscribe an area and is not a polygon.

```{r create-polygons}
xy <- rbind(
  cbind(12.39585, 51.31866),
  cbind(12.39584, 51.31865),
  cbind(12.39584, 51.31866),
  cbind(12.39585, 51.31866)
)
pol <- vect(xy) |> as.lines() |> as.polygons()
```

```{r geometries-plot, fig.align='center'}
plot(pol, col = "gold")
lines(lin, col = "red", lw = 5)
points(poi, col = "blue", cex = 1)
```

### Reading & Writing Geometries

In most cases, you will not create your own geometry by hands, but load geometries from files.
To read geometries from a file, use `vect()`.
```{r read-shapefile, fig.align='center'}
ger <- vect("data/germany.shp")  # shapefile with the country boundary of Germany
ger
```

To write geometries to a file, use `writeVector()`.

```{r, write-shapefile, eval=FALSE}
writeVector(ger, "data/germany.shp", overwrite = TRUE)  # if already exists you need overwrite = TRUE
```

## Rasters

Rasters are gridded areas where each grid pixel takes a value.
Rasters are useful because:

  - they compress the information of geometries to a manageable size. Imagine to have to work with building geometries *globally*. 
  - the data they represent is obtained in a gridded format. This is common for satellite data, for example.

When the data we are interested in are values on a gridded area, rasters are a better options than to using geometries, as they save a lot of memory and space on disk.
For example, if we want to represent landcover type over a large area(forest, agriculture, build-up, etc.), it is easier to grid the area into pixels and save the landcover type of each pixel rather than to create a geometry for each different structure.
```{r leipzig-landcover, class.source="fold-hide", fig.align='center', fig.width=7, fig.caption="Landcover map of Leipzig from DLR (German Aerospace Center)"}
landcover <- rast("data/landcover-2015.tif")
plot(landcover)  # from EOC of DLR
```
Rasters are saved in raster files (usually with extension `.tif`). 
In addition to the values of each grid, rasterfiles also contain metadata for the grid,  such as the its extent and coordinate reference system (we will talk about this later).
For instance, some of the metadata of the landcover raster:
```{r raster-metadata, class.source="fold-hide"}
landcover
```
Note the metadata `dimensions` (grid size), `resolution` (spatial resolution, in $m$ for this raster), 
and `extent` (spatial extent).

### Creating Rasters from Scratch
Simply put, rasters are matrices/arrays with associated spatial metadata.
In `terra`, use `rast()` to create a raster from a matrix.
```{r array, fig.align='center'}
m <- matrix(rnorm(100), nrow = 10, ncol = 10)  # 10x10 matrix
r <- rast(m)
plot(r)
```
Usually, you will not create rasters from scratch.
However, if you are familiar with R arrays, you will notice a nice properties that is inherited by rasters: rasters can have multiple layers, with each layer being a matrix.
```{r stack, fig.align='center', fig.width=8}
r <- rast(array(rnorm(200), dim = c(10, 10, 2)))  # 10x10x2 array
plot(r)
```

When an area has multiple rasters, it is possible to stack them to create a single raster object.
The rasters in the stack need to have all the same extent and coordinate reference system.
Use `c()` to stack rasters using `terra`.
```{r stack-c, fig.align='center', fig.width=8}
r1 <- rast(matrix(rnorm(100), nrow = 10, ncol = 10))
r2 <- rast(matrix(rnorm(100), nrow = 10, ncol = 10))
r <- c(r1, r2)  # a stack
plot(r)
```

### Reading & Writing Rasters
To read rasters into memory, use `rast()`.
```{r read-raster, fig.align='center'}
landcover <- rast("data/landcover-2015.tif")
landcover
```

To write rasters to disk, use `writeRaster()`.

```{r, write-raster, eval=FALSE}
writeRaster(landcover, "data/landcover-2015.tif", overwrite = TRUE, datatype = "INT1U")
```
Here, the argument `datatype = "INT1U"` (specifying the values in the grid are 1-byte unsigned integers) 
is needed because the rasters contains classes (levels).
In most cases, this argument is best left unspecified, as `terra` picks the optimal value by default.
Once you have used GIS for some time, you will notice that some of the rasters you downloaded have been scaled up to weird numbers, e.g. 65535.
This is because the creator of those rasters decided to save them as, e.g., 2-bytes unsigned integers, to make them smaller and, thus, easier to move around the internet.
If you need to deal with extremely big rasters, this trick may come in handy.

## Spatial metadata

Spatial objects always need certain metadata to be useful.
For example, a raster is of little help if there is not information of the area it covers.
The most important metadata are:

  1. Spatial extent: the four corners of the quadrilateral polygon that inscribe the object represented.
  2. Coordinate reference system: how the earth surface is represented.
  3. Resolution (for rasters only): the size of a pixel.

### Spatial extent
The spatial extent is the quadrilateral that inscribe the area of the spatial data.
The extent is usually represented by the coordinates of the four vertices of the quadrilateral, i.e. `xmin`, `xmax`, `ymin`, and `ymax`.
Use `ext()` to get the spatial extent of an object.
```{r ext}
landcover <- rast("data/landcover-2015.tif")
ext(landcover)
```
### Coordinate reference system

GIS try to represent the surface of the Earth, a 3D spheroid, onto a plane.
The coordinate reference system (CRS), also known as spatial reference system (SRS), defines how this _projection_ of a 3D object to a 2D one is achieved.
It is not possible to achieve this projection accurately and some distortions will always be present.
In particular, at least one of distance, angular conformity, and area will be distorted.
Projections can be grouped into types, depending on which property of the Earth surface they do not distort:

  - Conformal: they correctly represent the angles between points and, thus, shapes (e.g. ESRI:54004).
  - Equidistant: they correctly represent distances (e.g. ESRI:54002).
  - Equal-area: they correctly represent areas (e.g. ESRI:54034).

An overview of ESRI and EPSG^[ESRI stands for Environmental Systems Research Institute, Inc., which is the company that developed ArcGIS and created a code standard for projections. The other commonly used standard is maintained by the European Petroleum Survey Group (EPSG).] projections can be found at <https://spatialreference.org/>.
Wikipedia also has a nice list with the property of some projection: <https://en.wikipedia.org/wiki/List_of_map_projections>.

Use `crs()` to know the CRS of an object.
By default, `crs()` displays the CRS in Well Known Text (WKT) format.
```{r, crs}
crs(idiv, parse = TRUE)
```
Notice, among the others, the attributes `AREA` (the area of usage for the CRS) and `ID` (in this case, the EPSG code).
WKT is not very nice for humans; use the extra argument `proj = TRUE` to see the PROJ4 format of the CRS.
```{r crs-proj}
crs(idiv, proj = TRUE)
```
Use `project()` to project a spatial object from one CRS to another.
```{r project}
landcover <- project(landcover, crs("EPSG:4326"))
```

### Resolution

Resolution applies only to rasters, as geometries can be scaled at any level.
Use `res()` to get the resolution of a raster.
```{r res}
res(landcover)
```
The first value is the "horizontal" and the second is the "vertical" resolution.
The units of the output of `res()` is the same as the unit of the CRS, in this case $m$:
```{r unit}
crs(landcover, proj = TRUE)
```

# Reprojecting

It is quite common that data are obtained from a source that uses a CRS that is not ideal for analyses.
It is even more common that data are gathered from multiple sources that do not use the same CRS.
In such cases, the spatial data should be reprojected to one common CRS that is ideal for analyses.

Use `project()` to project a spatial object from one CRS to another.
Three types of arguments can be passed to `project()`:

  1. A spatial object with known CRS.
  2. A string with the WKT or PROJ4 CRS.
  3. A code of a known CRS, e.g. from the EPSG standard.

```{r reproject}
r <- rast("data/landcover-2015.tif")
germany <- vect("data/germany.shp")

germany <- project(germany, crs(r))  # a spatial object
germany_mollweide <- project(germany, "+proj=moll")  # a proj4
germany_4326 <- project(germany, "EPSG:4326")  # a CRS code
```
<blockquote class="nb">
When using an existing spatial object (`<obj>`) as CRS target, remember to use `project(<x>, crs(<obj>))` and not `project(<x>, <obj>)` if you are interested in reprojecting only. See section 5.3 about resampling for details.
</blockquote>

CRS have a big influence on analyses and visualization.
```{r, class.source="fold-hide", fig.align='center', fig.width=5, fig.height=5}
plot(buffer(vect(cbind(2e6, 3e6)), 4e6), col = "white", lw = 1e-6)
polys(germany, col = "grey90")
polys(germany_mollweide, col = "grey90")
polys(germany_4326, col = "grey90")
l <- vect(
  rbind(
    cbind(5e5, 5e5),
    cbind(0, 0)
  )
)
lines(l[1], l[2], arrows = TRUE, length = .1)
l <- vect(
  rbind(
    cbind(2e6, 2e6),
    cbind(0, 0)
  )
)
text(l[1], labels = "Cannot be seen,\nbut EPSG:4326 is here")
```
<blockquote class="nb">
Be sure to use the CRS that is best for your analyses or visualization.
</blockquote>

# Data Conversion

Sometimes is needed to create a raster from a geometry or *vice versa*.

## Geometries to Rasters

Use `rasterize()` to convert geometries to raster.
In addition to the geometry to rasterize, you need to pass a raster to function as template, i.e. from which extent, CRS, and resolution are extracted from.
```{r geom-to-rast}
landcover <- rast("data/landcover-2015.tif")
idiv <- vect("data/idiv.shp")
idiv <- project(idiv, crs(landcover))  # CRS needs to be the same
idiv_r <- rasterize(idiv, landcover, touches = TRUE)
```
If specified, `touches = TRUE` assigns a value of 1 to all cells that are touched by the polygon.
The extent of this new raster is the same as the landcover one, which is too big to actually see the raterized polygon.
Use `trim()` to trim the raster to the smallest raster containing all values that are not `NA`.
```{r trim, fig.align='center'}
plot(trim(idiv_r))
lines(idiv)
```

## Rasters to Geometries

Use `as.points()` or `as.polygons()` to convert rasters to geometries.
```{r rast-to-geom}
landcover <- crop(landcover, buffer(idiv, 1e2))  # restrict the area to something that can be plotted
poi <- as.points(landcover)
pol <- as.polygons(landcover)
```
```{r, class.source="fold-hide", fig.align='center', fig.width=10}
op <- par(no.readonly = TRUE)
par(mfrow = c(1, 2))
plot(poi, "category")
lines(idiv)
plot(pol, "category")
lines(idiv)
par(op)
```

# Geometry Operations
Commonly operations on geometries are to calculate their length and area, find their centroids, calculate distance, and buffering them.

## Length
Use `perim()` to obtain the length of lines or the perimeter of polygons.
```{r perim}
perim(idiv)
idiv |> disagg(segments = TRUE) |> perim() |> sum()  # disagg(segments = TRUE) split the polygon into lines
```
The units are defined by the CRS.
<blockquote class="nb">
It is best to project the geometry to a longitude/latitude CRS to get more accurate results.
</blockquote>
```{r perim-projected}
idiv |> project("EPSG:4326") |> perim()  # difference of 3 mm 
```

## Area
Use `expanse()` to obtain the area of polygons.
```{r area}
expanse(idiv)
```
The units are defined by the CRS.
<blockquote class="nb">
It is best to project the geometry to a longitude/latitude CRS to get more accurate results.
</blockquote>
```{r area-projected}
idiv |> project("EPSG:4326") |> expanse()  # same result, as CRS was equal-area
```

## Centroid
The centroid of a geometry is the point defined as the arithmetic mean position of all the points on the surface of the geometry.
Use `centroids()` to get the centroids of the geometries.
```{r centroids, fig.align='center'}
centr <- centroids(idiv)
plot(idiv, col = "blue")
points(centr, bg = "gold", cex = 2, pch = 21)
```

For concave polygons, the centroid may lay outside of the polygon itself
```{r centroid-concave, fig.align='center'}
p <- vect(matrix(c(0, 0, 1, 0, 1, 1, 0.9, 0.1, 0, 0), byrow = TRUE, ncol = 2)) |> 
  as.lines() |> 
  as.polygons()
centr <- centroids(p)
plot(p, col = "blue")
points(centr, bg = "gold", cex = 2, pch = 21)
```

Specify `centroids(inside = TRUE)` to force the "centroid" to be inside the polygon.
```{r centroid-inside, fig.align='center'}
p <- vect(matrix(c(0, 0, 1, 0, 1, 1, 0.9, 0.1, 0, 0), byrow = TRUE, ncol = 2)) |> 
  as.lines() |> 
  as.polygons()
centr <- centroids(p, inside = TRUE)
plot(p, col = "blue")
points(centr, bg = "gold", cex = 2, pch = 21)
```

## Distance
Use `distance()` to get the distances between geometries
When passing only an object will multiple geometries, distances will be calculated among each geometry and a (symmetric) matrix is returned.
```{r distance-one}
poi <- vect(matrix(rnorm(10), ncol = 2), crs = "EPSG:4326")  # 5 random points
poi |> distance() |> as.matrix()
```

When passing also a second geometry, distances will be calculated among each geometry of the first object and each geometry of the second object.
```{r distance-two}
distance(
  poi,
  idiv |> project("EPSG:4326") |> centroids()
)
```

## Buffer
The buffer of a geometry is obtained by extending the geometry perpendicular to the tangent line of its side.
It is easier to see it than to explain it.
Use `buffer()` to buffer geometries.
```{r buffer, fig.align='center'}
b <- buffer(idiv, 10)  # 10 meters
plot(b, col = "gold")
polys(idiv, col = "blue")
```

## Exercise
Find the centroid of Germany, how far is from the centroid of the main iDiv bulding, and plot the circle centered at the centroid with the smallest area that is touching the centroid of the iDiv building.
The geometry of Germany is saved in `data/germany.shp`.
The geometry of the iDiv building is saved in `data/idiv.shp`.
Click on the "Code" button below to see a solution to this problem.

```{r example-geometry-operation, fig.align='center', fig.width=7, fig.height=7, class.source="fold-hide"}
ger <- vect("data/germany.shp")
idiv <- vect("data/idiv.shp")

centr <- centroids(ger)  # centroid of Germany
idiv_centr <- idiv |> project(crs(ger)) |> centroids()  # centroid of iDiv
d <- distance(centr, idiv_centr)  # distance between centroids
b <- buffer(centr, d)  # circle with the smallest area touching iDiv
l <- as.lines(rbind(centr, idiv_centr))  # line connecting centroids

plot(ger)
polys(b, col = adjustcolor("blue", alpha.f = .5))
lines(l)
points(centr, pch = 21, cex = 2, bg = "gold")
points(idiv_centr, pch = 21, cex = 2, bg = "green")
text(centr, "Germany\ncentroid", pos = 2)
text(idiv_centr, "iDiv\ncentroid", pos = 4)
text(l, paste(round(d) / 1e3, "km"), pos = 3)
text(b, paste("Area =", round(expanse(b) / 1e6), "km^2"), pos = 3, offset = 5)
```

# Raster Operations

Commonly operations on rasters are to calculate summary statistics, aggregate or disaggregate to different resolutions, resampling, and interpolation.

## Summary Statistics {.tabset}

### Local Summary
A local summary is calculated across pixels with the same coordinates i.e. locally.
Raster stacks can be summarized using common function, such as `mean`, `sd`, `sum`, etc.
The output is a single raster layer with the summary.
Mean, sum, minimum, and maximum, can be calculated simply using `mean()`, `sum()`, etc.
For other function, use `app()`.
```{r local, fig.align='center', fig.width=6, fig.height=6}
ndvi <- rast("data/ndvi-2024.tif")
avg_ndvi <- mean(ndvi, na.rm = TRUE)
std_ndvi <- app(ndvi, "sd", na.rm = TRUE)
month_max_ndvi <- app(ndvi, "which.max", na.rm = TRUE)  # month with the maximum NDVI
plot(avg_ndvi, col = colorRampPalette(c("dodgerblue3", "orange", "darkgreen"))(100))
plot(std_ndvi, col = hcl.colors(100, "Reds", rev = TRUE))
```

### Global Summary
Global summaries are calculated across all pixels of a layer.
Use `global()` to get global summaries.
When the input is a raster stack, the global summary is calculated for each layer separately.
```{r global}
global(ndvi, "mean", na.rm = TRUE)
```

### Zonal Summary
Zonal statistics summarize the values of a raster using categories from another raster of geometry.
Use `zonal()` to obtain zonal statistics.
Two arguments (`<x>`, `<y>`) are always required for `zonal(<x>, <y>)`, with `<x>` being the raster with the values to summarize and `<y>` the raster/geometry specifying the categories for the summary.
```{r zonal}
landcover <- rast("data/landcover-2015.tif")
avg_ndvi <- project(avg_ndvi, landcover)  # this will also resample avg_ndvi (see the section Resampling)
zonal(avg_ndvi, landcover, fun = "mean", na.rm = TRUE)
```

## Aggregate and Disaggregate {.tabset}

### Aggregate
Aggregating creates a raster that is at coarser resolution compared to the original raster.
Use `aggregate()` to aggregate rasters.
The arguments `fact`, number of cells in each direction to be aggregated, and `fun`, the function used for aggregatation, need to be specified.
```{r aggregate, fig.align='center', fig.width=12, fig.height=6}
r <- rast(matrix(rnorm(16^2), 16, 16))
r_aggr <- aggregate(r, 4, "max")  # maximum values in the 4x4 grid

par(mfrow = c(1, 2))  # cannot stack rasters with different resolution
plot(r)
plot(r_aggr)
par(mfrow = c(1, 1))
```

### Disaggregate
Disaggregating creates a raster that is at finer resolution compared to the original raster.
Use `disagg()` to disaggregate rasters.
The arguments `fact`, number of cells in each direction to create for each cell of the original raster, and `method`, the method used for disaggregation, need to be specified.
Available methods are `near`, for nearest neighbor, or `bilinear`, for bilinear interpolation.
```{r disagg, fig.align='center', fig.width=12, fig.height=6}
r_disagg <- disagg(r, 4, method = "bilinear")

par(mfrow = c(1, 2))  # cannot stack rasters with different resolution
plot(r)
plot(r_disagg)
par(mfrow = c(1, 1))
```

<blockquote class="nb">
Aggregating and disaggregating a raster does not give, in general, the same raster back. Some of the original information is lost during aggregation.
</blockquote>
```{r agg-disagg, fig.align='center', fig.width=12, fig.height=6}
plot(c(r, r |> aggregate(4, "mean") |> disagg(4, "bilinear")))
```

### Exercise
Assess how global average of NDVI is affected by the resolution of the NDVI layers.
Aggregate the NDVI layer by a factor `seq(2, 20, by = 1)` and see if the global average change.
Click on the "Code" button below to see a solution to this problem.

```{r, class.source="fold-hide", fig.align='center', fig.width=5, fig.height=5}
ndvi <- rast("data/ndvi-2024.tif") |> mean()
global_avg_ndvi <- rep(NA, 20)
global_avg_ndvi[1] <- (ndvi |> global("mean", na.rm = TRUE))[1, 1]
for (f in 2:20) {
  global_avg_ndvi[f] <- (ndvi |> aggregate(fact = f) |> global("mean", na.rm = TRUE))[1, 1]
}
global_avg_ndvi <- data.frame(
  fact = 1:20,
  avg_ndvi = global_avg_ndvi
)
scatter.smooth(global_avg_ndvi, ylim = c(0, .5))
```
The average NDVI is not changing.
This is a property of the average.
Try instead to see if the standard deviation changes.

```{r, class.source="fold-hide", fig.align='center', fig.width=5, fig.height=5}
ndvi <- rast("data/ndvi-2024.tif") |> mean()
global_std_ndvi <- rep(NA, 20)
global_std_ndvi[1] <- (ndvi |> global("sd", na.rm = TRUE))[1, 1]
for (f in 2:20) {
  global_std_ndvi[f] <- (ndvi |> aggregate(fact = f) |> global("sd", na.rm = TRUE))[1, 1]
}
global_std_ndvi <- data.frame(
  fact = 1:20,
  std_ndvi = global_std_ndvi
)
scatter.smooth(global_std_ndvi, ylim = c(0.1, .3))
```
The standard deviation decreases for increasing aggregation factor.
This is because aggregating is done here (implicitly) using `mean` as the aggregating function.
This reduces spatial heterogeneity and, therefore, the global standard deviation.
Scale is important for some processes, but not others.

## Resampling
When two rasters do not align, i.e. they have different origin or resolution, to make them comparable one of them must be resampled.
Resampling transform one of the two rasters to a raster that align with the other.
Use `resample()` to resample rasters.
The argument `method` is used to specify the algorithm used for resampling.
Among the available algorithms are:

  - `near`, for nearest neighbor.
  - `bilinear`, for bilinear interpolation.
  - `cubic`, for cubic interpolation.
  - `cubicspline`, for cubic-spline interpolation.
  - `lanczos`, for Lanczos resampling.

```{r resampling, fig.align='center', fig.width=6, fig.height=6, cache=TRUE}
landcover <- rast("data/landcover-2015.tif")
ndvi <- rast("data/ndvi-2024.tif") |>
  mean(na.rm = TRUE) |>
  project(crs(landcover))

ndvi_resampled <- resample(ndvi, landcover, method = "lanczos")

plot(ndvi_resampled, col = colorRampPalette(c("dodgerblue3", "orange", "darkgreen"))(100))
```

<blockquote class="nb">
The difference between `project(x, crs(y))` and `project(x, y)` is that the first only project the CRS, whereas the second actually resample `x` to `y`.
In many cases `resample(x, y, method = <method>)` can be avoided by using `project(x, y, method = <method>)`
</blockquote>

## Interpolation
Interpolation uses a statistical model to make geographic predictions.
A simple statistical model can include, for example, the coordinates of the grid.
This works relatively well with processes that change gradually with longitude or latitude, such as temperature.
```{r interpolation, fig.align='center', fig.width=12, fig.height=6}
tas <- rast("data/wc2-bio1.tif")  # average annual temperature, Celsius
elev <- rast("data/wc2-elevation.tif")  # elevation, meters

par(mfrow = c(1, 2))
plot(tas, col = hcl.colors(100, "Zissou 1"))
plot(elev, col = map.pal("haxby", 5))
plot(elev, col = colorRampPalette(c("forestgreen", "#CDFFA2", "#FFAF4D", "#FFFFFF"))(100))
par(mfrow = c(1, 1))

r <- c(tas, elev)

# construct table for model fitting
xy <- xyFromCell(r, 1:ncell(r))
xy <- cbind(xy, extract(r, xy, cells = TRUE))

# fit a simple linear model with coordinates
model <- lm(tas ~ x * y + elevation, data = xy)

# interpolate
interpolated <- interpolate(r, model)
interpolated <- mask(interpolated, tas)  # remove sea and large water bodies
names(interpolated) <- "tas_interpolated"
plot(c(tas, interpolated), col = hcl.colors(100, "Zissou 1"))
```

Considering the simplicity of the underlying model, the interpolation works quite well.
```{r interpolated-plot, fig.align='center', fig.width=6, fig.height=6}
# Prediction errors
# In red, over-predictions
# In blue, under-predictions
plot(interpolated - tas, col = hcl.colors(100, "Blue-Red 3"))
```

# Examples

## Species Distribution Model (SDM)
I will show how to perform a simple species distribution model (SDM) for the species _Erica arborea_.

<img src="figures/erica-arborea.JPG" alt="erica-arborea" height="300px"/>
<img src="figures/erica-arborea-flowers.jpg" alt="flowers" height="300px"/>

I load the libraries.
```{r erica-libraries}
library(tibble)
library(dplyr)
library(readr)
library(terra)
```

I load the file downloaded from GBIF and convert it to a geometry (points).
```{r erica-gbif}
gbif <- read_tsv("data/erica-arborea-gbif.tsv") |> 
  select("decimalLongitude", "decimalLatitude") |>
  vect(
    geom = c("decimalLongitude", "decimalLatitude"),
    crs = "+proj=longlat +datum=WGS84"  # I know this is GBIF CRS
  )
```

I load the bioclimatic variables from WorldClim.
```{r erica-template}
bios <- rast("data/bios.tif")

# I also create a template of the land
land <- bios[[1]]
land[!is.na(land)] <- 1
names(land) <- "land"
```

I thin the GBIF data retaining only one point per grid cell.
```{r erica-thin}
gbif <- extract(land, gbif, cells = TRUE, xy = TRUE) |> 
  as_tibble() |> 
  filter(!is.na(land)) |> 
  group_by(cell) |> 
  slice_sample(n = 1) |> 
  ungroup() |> 
  select("x", "y") |> 
  vect(geom = c("x", "y"), crs = "+proj=longlat +datum=WGS84")
```

I sample pseudo-absences randomly in the polygon that contains all GBIF observation, buffered to 100 km.
```{r erica-absences}
range <- gbif |> convHull()
abs <- spatSample(buffer(range, 1e5), length(gbif) * 2)
abs <- extract(land, abs, cells = TRUE, xy = TRUE) |> 
  as_tibble() |> 
  filter(!is.na(land)) |> 
  group_by(cell) |> 
  slice_sample(n = 1) |> 
  ungroup() |> 
  select("x", "y") |> 
  slice_sample(n = length(gbif)) |> 
  vect(geom = c("x", "y"), crs = "+proj=longlat +datum=WGS84")
```

I prepare the data frame to be used for fitting the SDM.
```{r erica-prepdata}
gbif$occ <- 1
abs$occ <- 0
p <- rbind(gbif, abs)
d <- extract(bios, p, ID = FALSE) |> as_tibble()
d
```

```{r erica-map, fig.align='center', fig.width=6, fig.height=6}
plot(land, col = "grey90", legend = FALSE)
points(p, col = ifelse(p$occ == 0, "darkblue", "gold2"))
lines(buffer(range, 1e5))
```

I run the SDM, in this case a simple GLM.
I use only some of the bioclimatic variables^[This is just an example, and you should do better than this.].
```{r erica-model}
d <- d[, c("BIO01", "BIO04", "BIO12", "BIO15")]
d$occ <- p$occ
sdm <- glm(occ ~ ., data = d, family = "binomial")
summary(sdm)
```

I use the model to predict the suitability of the species in geographic space.
```{r erica-predictions, fig.align='center', fig.width=6, fig.height=6}
suitability <- predict(bios, sdm, type = "response")
plot(
  suitability,
  col = hcl.colors(100, "Geyser", rev = TRUE),
  breaks = seq(0, 1, by = .02),
  type = "continuous",
  main = "Predicted suitability"
)
```

Zooming on the Mediterranean regions.
```{r erica-zoomed, fig.align='center', fig.width=6, fig.height=6}
plot(
  crop(suitability, ext(-9, 24, 35, 50)),
  col = hcl.colors(100, "Geyser", rev = TRUE),
  breaks = seq(0, 1, by = .02),
  type = "continuous",
  main = "Predicted suitability"
)
points(p[p$occ == 1, ], cex = .3)
```

## Species Distribution Model (SDM)
I will show how to perform a simple species distribution model (SDM) for the species _Erica arborea_.

<img src="figures/erica-arborea.JPG" alt="erica-arborea" height="300px"/>
<img src="figures/erica-arborea-flowers.jpg" alt="flowers" height="300px"/>

```{r pseuforca-load}
library(terra)
library(dplyr)
library(tibble)

pal <- adjustcolor(hcl.colors(17, "Set 2"), alpha.f = .3)

p <- vect("data/movebank.shp")
# p$individual <- p$ind_ident
# p <- p[, c("timestamp", "individual")]
# p <- p[order(p$timestamp), ]
# p <- p[order(p$individual), ]
# writeVector(p, "data/movebank.shp", overwrite = TRUE)
p$timestamp <- as.POSIXct(p$timestamp, format = c("%Y-%m-%d %H:%M:%S"))

plot(p, "individual", col = pal)

homeranges <- convHull(p, by = "individual")
plot(homeranges, "individual", pal)
points(p, alpha = .1)

overlap_area <- function(shape1, shape2) {
  intersection <- suppressWarnings(terra::intersect(shape1, shape2))
  if (length(intersection) == 1) {
    area <- expanse(intersection, unit = "km")  # km2
  } else {
    area <- 0
  }
  return(area)
}
overlap <- matrix(NA, ncol = length(homeranges), nrow = length(homeranges))
colnames(overlap) <- homeranges$individual
rownames(overlap) <- homeranges$individual
for (i in seq_len(length(homeranges$individual))) {
  for (j in seq(i, length(homeranges$individual))) {
    overlap[i, j] <- overlap_area(homeranges[i], homeranges[j])
    overlap[j, i] <- overlap[i, j]
  }
}
overlap

par(mfrow = c(1, 2))
clusters <- hclust(dist(1 / (overlap + 1e-6)), method = "average")
plot(clusters)  # 3 groups
k <- 3
groups <- cutree(clusters, k)
groups
plot(homeranges, col = hcl.colors(k, "Set 2")[groups], alpha = .5)
text(homeranges, names(homeranges))
```
